---
title: "03-RR-Nature-PlayWorkRhetoric"
author: "Anoff Nicholas Cobblah"
date: "July 31, 2018"
output: html_document
  html_document:
    number_sections: yes
    toc: true
    toc_depth: 6
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##### March 2018: "play", "player", "recreation", "work", "worker", and "labor" in *Nature*

This script combines my Word Flagging and KWIC (tokenizer script) methods in order to create an interactive illustration of the frequency with which the terms "play", "player", "recreation", "work", "worker", and "labor" were referenced in *Nature*. The goal is to determine the context for work and play rhetoric in that publication.

```{r Nature Parameters,  eval=FALSE}
    Naturelocation <- paste0(getwd(),"/Applications/Victorian-Professional-Science-Writing/Nature")
    Naturedoclocation <- paste0(Naturelocation,"/Documents")
    Naturelongconlength <- 250
    Natureshortconlength <- 3
    NaturePOSconlength <- 10
    Natureplaysearchedtermlist <- c("play", "player", "recreation")
    Natureworksearchedtermlist <- c("work", "worker","labor")
    Naturesearchedtermlist <- c(Natureplaysearchedtermlist,Natureworksearchedtermlist)
    Natureoutputlocation <- Naturelocation
    NatureWordFlagdfPath <- paste0(Natureoutputlocation,"/","NatureWordFlagdf.txt")
    NatureDocumentSize <- 400296165
```

**IMPORTANT NOTE: Since creating a Word Flag matrix can take a nontrivial amount of time for larger corpuses, this script is designed only to run the program to create a new NatureWordFlagdf if there is a change to the dataset in folder "Documents" or if the previous NatureWordFlagdf has been deleted.**

To create the data frame compiling every reference to a term, run the following script.

```{r MarNatureApp Word Flag,  eval=FALSE}
      if(sum(file.info(list.files(Naturedoclocation, all.files = TRUE, recursive = TRUE, full.names=TRUE))$size) == NatureDocumentSize) {
        NatureDataChange1 <- FALSE
        print("The data in the 'Documents' folder appears not to have changed.")
      }else{
        NatureDataChange1 <- TRUE
        print("The data in the 'Documents' folder appears to have been changed. A new NatureWordFlagdf will therefore be created. TO UPDATE THIS SCRIPT, PLEASE CHANGE THE NatureDocumentSize TO REFLECT THE NEW SIZE OF THE DOCUMENTS.")
        }
      
      if(file.exists(NatureWordFlagdfPath) == TRUE) {
        NatureDataChange2 <- FALSE
        print("The previous NatureWordFlagdf still exists.")
      }else{
        NatureDataChange2 <- TRUE
        print("The previous NaturewordFlagdf seems to have been moved or deleted.  A new NatureWordFlag will therefore be created.")
        }

  if(NatureDataChange1|NatureDataChange2 == TRUE) {
  
      files <- list.files(path = Naturedoclocation, pattern = "txt", full.names = TRUE) #creates vector of txt file names.
      if(file.exists(Natureoutputlocation) == FALSE){dir.create(Natureoutputlocation)}
      Naturestemsearchedtermlist <- unique(wordStem(Naturesearchedtermlist)) #lemmatizes the list of terms you want to search for.
      NatureWordFlagmat <- matrix(,ncol=12,nrow=1)
      for (i in 1:length(files)) {
        fileName <- read_file(files[i])
        Encoding(fileName) <- "UTF-8"  #since tokenize_sentences function requires things to be encoded in UTF-8, need to remove some data.
        fileName <- iconv(fileName, "UTF-8", "UTF-8",sub='')
        ltoken <- tokenize_words(fileName, lowercase = TRUE, stopwords = NULL, simplify = FALSE)
        ltoken <- unlist(ltoken)
        stemltoken <- wordStem(ltoken) #this uses the Snowball library to lemmatize the entire text.
        textID <- i
        for (p in 1:length(Naturestemsearchedtermlist)) {
          Naturestemsearchedterm <- Naturestemsearchedtermlist[p]
          for (j in 1:length(stemltoken)) {
              if (Naturestemsearchedterm == stemltoken[j]) {
                if (j <= Naturelongconlength) {longtempvec <- ltoken[(1:(j+Naturelongconlength))]}
                if (j > Naturelongconlength) {longtempvec <- ltoken[(j-Naturelongconlength):(j+Naturelongconlength)]}
                if (j <= Natureshortconlength) {shorttempvec <- ltoken[(1:(j+Natureshortconlength))]}
                if (j > Natureshortconlength) {shorttempvec <- ltoken[(j-Natureshortconlength):(j+Natureshortconlength)]}
                if (j <= NaturePOSconlength) {POStempvec <- ltoken[(1:(j+NaturePOSconlength))]}
                if (j > NaturePOSconlength) {POStempvec <- ltoken[(j-NaturePOSconlength):(j+NaturePOSconlength)]}
                TempTextName <- gsub(paste0(Naturedoclocation,"/"),"",files[i]) #This grabs just the end of the file path.
                TempTextName <- gsub(".txt","",TempTextName) #This removes the .txt from the end of the name.
                temprow <- matrix(,ncol=12,nrow=1)
                colnames(temprow) <- c("Text", "Text_ID", "Naturestemsearchedterm","Lemma","Lemma_Perc","KWIC","Total_Lemma","Date","Category","Short_KWIC","POS_KWIC","Current_Date")
                temprow[1,1] <- TempTextName
                temprow[1,2] <- textID
                temprow[1,3] <- Naturestemsearchedterm
                temprow[1,4] <- j
                temprow[1,5] <- (j/length(stemltoken))*100
                temprow[1,6] <- as.character(paste(longtempvec,sep= " ",collapse=" "))
                temprow[1,7] <- length(stemltoken)
                temprow[1,8] <- strsplit(TempTextName,"_")[[1]][1]
                #Determining Category
                  if(Naturestemsearchedterm %in% wordStem(Natureplaysearchedtermlist)) {temprow[1,9] <- "Play-Rhetoric"}
                  if(Naturestemsearchedterm %in% wordStem(Natureworksearchedtermlist)) {temprow[1,9] <- "Work-Rhetoric"}
                temprow[1,10] <- as.character(paste(shorttempvec,sep= " ",collapse=" "))
                temprow[1,11] <- as.character(paste(POStempvec,sep= " ",collapse=" "))
                temprow[1,12] <- format(Sys.time(), "%Y-%m-%d")
                NatureWordFlagmat <- rbind(NatureWordFlagmat,temprow)
              }
          }
        }
        print(paste0(i," out of ",length(files))) #let's user watch as code runs for long searches
      }
      NatureWordFlagmat <- NatureWordFlagmat[-1,]
      NatureWordFlagdf <- as.data.frame(NatureWordFlagmat)
      write.table(NatureWordFlagdf, NatureWordFlagdfPath)
      NatureWordFlagdf[1:5,]
  }else{
    print("Loading the previous dataset as NatureWordFlagdf")
    NatureWordFlagdf <- read.table(NatureWordFlagdfPath)
  }
NatureWordFlagdf
```

We can then add up the values in NatureWordFlagdf to make a table of the frequency of play and work rhetoric, NatureFreqmat. It's important to do it this way because it allows us to choose a random KWIC.

```{r NatureFreqmat,  eval=FALSE}
  # Adding values from NatureWordFlagdf together to get a matrix of normalized frequencies for each category, as NatureFreqmat
  NatureWordFlagPlaydf <- NatureWordFlagdf[grep("Play-Rhetoric",NatureWordFlagdf$Category),]
      NatureWordFlagWorkdf <- NatureWordFlagdf[grep("Work-Rhetoric",NatureWordFlagdf$Category),]
      NatureFreqmat <- matrix(,ncol=9,nrow=1)
      files <- list.files(path = Naturedoclocation, pattern = "txt", full.names = TRUE)
      for (i in 1:length(files)) {
        TempTextName <- gsub(paste0(Naturedoclocation,"/"),"",files[i]) #This grabs just the end of the file path.
        TempTextName <- gsub(".txt","",TempTextName) #This removes the .txt from the end of the name.
        tempplaydf <- NatureWordFlagPlaydf[grep(TempTextName,NatureWordFlagPlaydf$Text),]
        tempworkdf <- NatureWordFlagWorkdf[grep(TempTextName,NatureWordFlagWorkdf$Text),]
        TempDate <- strsplit(TempTextName,"_")[[1]][1]
        TempLength <- tempplaydf$Total_Lemma[1]
        temprows <- matrix(,ncol=9,nrow=2)
        colnames(temprows) <- c("Text", "Text_ID","Date","Category","Frequency","Total_Lemma","Normalized_Freq","Sample_KWIC","Avg_Lemma_Perc")
        temprows[1:2,1] <- as.character(TempTextName)
        temprows[1:2,2] <- i
        temprows[1:2,3] <- as.character(TempDate)
        temprows[1,4] <- "Play-Rhetoric"
        temprows[2,4] <- "Work-Rhetoric"
        temprows[1,5] <- nrow(tempplaydf)
        temprows[2,5] <- nrow(tempworkdf)
        temprows[1:2,6]<- as.character(TempLength)
        temprows[1,7] <- (as.numeric(temprows[1,5])/as.numeric(temprows[1,6]))*100
        temprows[2,7] <- (as.numeric(temprows[2,5])/as.numeric(temprows[2,6]))*100
        #temprows[1,8]
          if(nrow(tempplaydf) > 0){temprows[1,8] <- as.character(sample(tempplaydf$Short_KWIC,1))}else{temprows[1,8] <- NA}
        #temprows[2,8]
          if(nrow(tempworkdf) >0) {temprows[2,8] <- as.character(sample(tempworkdf$Short_KWIC,1))}else{temprows[2,8] <- NA}
        temprows[1,9] <- mean(as.numeric(as.character(tempplaydf$Lemma_Perc)))
        temprows[2,9] <- mean(as.numeric(as.character(tempworkdf$Lemma_Perc)))
        NatureFreqmat <- rbind(NatureFreqmat,temprows)
      }
      NatureFreqmat <- NatureFreqmat[-1,]
      NatureFreqdf <- as.data.frame(NatureFreqmat)
      NatureFreqdf
```

With the data in hand, we can now ask some questions about our corpus, such as: Do references to play or work rhetoric in *Nature* increase over the course of its run? (Note that here I'm using the substr() function to just pull the year from the date). **AS EXPECTED, WE FIND THAT WORK RHETORIC INCREASES, WHILE PLAY STAYS BASICALLY THE SAME.** 

```{r NatureWordFreqmat Visual,  eval=FALSE}
# Visualizing NatureFreqdf BY DATE
      p <- ggplot(NatureFreqdf, aes(y = as.numeric(as.character(Normalized_Freq)), x = as.numeric(substr(Date,1,4)), color = Category, label = Sample_KWIC))
      pg <- geom_point(size=1,pch = 16)
      pl <- p + pg + labs(x = "Date", y = "Normalized Frequency (% of Words in Text)", title = "Appearances of Play and Work Rhetoric within Nature")
      ggplotly(pl)
```

We can also visualize the terms which most frequently occur around the search terms in the two categories within this corpus. Interestingly, work associated with "science" and "london", and more gendered terms.
```{r Nature Work/Play association,  eval=FALSE}
NatureWordFlagdf$KWIC <- as.character(NatureWordFlagdf$KWIC)
NatureWordFlagdf$Text <- as.character(NatureWordFlagdf$Text)
corpus <- corpus(NatureWordFlagdf, 
                 docid_field="Text", 
                 text_field="KWIC")
group_NatureWordFlagdfm <- dfm(corpus, remove=c(stopwords("en"),Naturesearchedtermlist), remove_punct=TRUE, remove_numbers = TRUE, groups="Category")
textplot_wordcloud(group_NatureWordFlagdfm,max.words=50, colors = RColorBrewer::brewer.pal(8,"Dark2"), comparison=TRUE)
```