---
title: "05-RR-PhilosophicalMagazine-PlayWorkRhetoric"
author: "Anoff Nicholas Cobblah"
date: "July 31, 2018"
output: html_document
  html_document:
    number_sections: yes
    toc: true
    toc_depth: 6
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##### **PROVISIONAL** March 2018: "play", "player", "recreation", "work", "worker", and "labor" in *Philosophical Magazine* (SOME FILES NEED TO BE SEPARATED INTO 2 PARTS)

This script combines my Word Flagging and KWIC (tokenizer script) methods in order to create an interactive illustration of the frequency with which the terms "play", "player", "recreation", "work", "worker", and "labor" were referenced in the *Philosophical Magazine*. The goal is to determine the context for work and play rhetoric in that publication.

```{r PhilMag Parameters,  eval=FALSE}
    PhilMaglocation <- paste0(getwd(),"/Applications/Victorian-Professional-Science-Writing/Philosophical-Magazine")
    PhilMagdoclocation <- paste0(PhilMaglocation,"/Documents")
    PhilMaglongconlength <- 250
    PhilMagshortconlength <- 3
    PhilMagPOSconlength <- 10
    PhilMagplaysearchedtermlist <- c("play", "player", "recreation")
    PhilMagworksearchedtermlist <- c("work", "worker","labor")
    PhilMagsearchedtermlist <- c(PhilMagplaysearchedtermlist,PhilMagworksearchedtermlist)
    PhilMagoutputlocation <- PhilMaglocation
    PhilMagWordFlagdfPath <- paste0(PhilMagoutputlocation,"/","PhilMagWordFlagdf.txt")
    PhilMagDocumentSize <- 492677179
```

**IMPORTANT NOTE: Since creating a Word Flag matrix can take a nontrivial amount of time for larger corpuses, this script is designed only to run the program to create a new PhilMagWordFlagdf if there is a change to the dataset in folder "Documents" or if the previous PhilMagWordFlagdf has been deleted.**

To create the data frame compiling every reference to a term, run the following script.

```{r MarPhilMagApp Word Flag,  eval=FALSE}
      if(sum(file.info(list.files(PhilMagdoclocation, all.files = TRUE, recursive = TRUE, full.names=TRUE))$size) == PhilMagDocumentSize) {
        PhilMagDataChange1 <- FALSE
        print("The data in the 'Documents' folder appears not to have changed.")
      }else{
        PhilMagDataChange1 <- TRUE
        print("The data in the 'Documents' folder appears to have been changed. A new PhilMagWordFlagdf will therefore be created. TO UPDATE THIS SCRIPT, PLEASE CHANGE THE PhilMagDocumentSize TO REFLECT THE NEW SIZE OF THE DOCUMENTS.")
        }
      
      if(file.exists(PhilMagWordFlagdfPath) == TRUE) {
        PhilMagDataChange2 <- FALSE
        print("The previous PhilMagWordFlagdf still exists.")
      }else{
        PhilMagDataChange2 <- TRUE
        print("The previous PhilMagwordFlagdf seems to have been moved or deleted.  A new PhilMagWordFlag will therefore be created.")
        }

  if(PhilMagDataChange1|PhilMagDataChange2 == TRUE) {
  
      files <- list.files(path = PhilMagdoclocation, pattern = "txt", full.names = TRUE) #creates vector of txt file names.
      if(file.exists(PhilMagoutputlocation) == FALSE){dir.create(PhilMagoutputlocation)}
      PhilMagstemsearchedtermlist <- unique(wordStem(PhilMagsearchedtermlist)) #lemmatizes the list of terms you want to search for.
      PhilMagWordFlagmat <- matrix(,ncol=12,nrow=1)
      for (i in 1:length(files)) {
        fileName <- read_file(files[i])
        Encoding(fileName) <- "UTF-8"  #since tokenize_sentences function requires things to be encoded in UTF-8, need to remove some data.
        fileName <- iconv(fileName, "UTF-8", "UTF-8",sub='')
        ltoken <- tokenize_words(fileName, lowercase = TRUE, stopwords = NULL, simplify = FALSE)
        ltoken <- unlist(ltoken)
        stemltoken <- wordStem(ltoken) #this uses the Snowball library to lemmatize the entire text.
        textID <- i
        for (p in 1:length(PhilMagstemsearchedtermlist)) {
          PhilMagstemsearchedterm <- PhilMagstemsearchedtermlist[p]
          for (j in 1:length(stemltoken)) {
              if (PhilMagstemsearchedterm == stemltoken[j]) {
                if (j <= PhilMaglongconlength) {longtempvec <- ltoken[(1:(j+PhilMaglongconlength))]}
                if (j > PhilMaglongconlength) {longtempvec <- ltoken[(j-PhilMaglongconlength):(j+PhilMaglongconlength)]}
                if (j <= PhilMagshortconlength) {shorttempvec <- ltoken[(1:(j+PhilMagshortconlength))]}
                if (j > PhilMagshortconlength) {shorttempvec <- ltoken[(j-PhilMagshortconlength):(j+PhilMagshortconlength)]}
                if (j <= PhilMagPOSconlength) {POStempvec <- ltoken[(1:(j+PhilMagPOSconlength))]}
                if (j > PhilMagPOSconlength) {POStempvec <- ltoken[(j-PhilMagPOSconlength):(j+PhilMagPOSconlength)]}
                TempTextName <- gsub(paste0(PhilMagdoclocation,"/"),"",files[i]) #This grabs just the end of the file path.
                TempTextName <- gsub(".txt","",TempTextName) #This removes the .txt from the end of the name.
                temprow <- matrix(,ncol=12,nrow=1)
                colnames(temprow) <- c("Text", "Text_ID", "PhilMagstemsearchedterm","Lemma","Lemma_Perc","KWIC","Total_Lemma","Date","Category","Short_KWIC","POS_KWIC","Current_Date")
                temprow[1,1] <- TempTextName
                temprow[1,2] <- textID
                temprow[1,3] <- PhilMagstemsearchedterm
                temprow[1,4] <- j
                temprow[1,5] <- (j/length(stemltoken))*100
                temprow[1,6] <- as.character(paste(longtempvec,sep= " ",collapse=" "))
                temprow[1,7] <- length(stemltoken)
                temprow[1,8] <- strsplit(TempTextName,"_")[[1]][1]
                #Determining Category
                  if(PhilMagstemsearchedterm %in% wordStem(PhilMagplaysearchedtermlist)) {temprow[1,9] <- "Play-Rhetoric"}
                  if(PhilMagstemsearchedterm %in% wordStem(PhilMagworksearchedtermlist)) {temprow[1,9] <- "Work-Rhetoric"}
                temprow[1,10] <- as.character(paste(shorttempvec,sep= " ",collapse=" "))
                temprow[1,11] <- as.character(paste(POStempvec,sep= " ",collapse=" "))
                temprow[1,12] <- format(Sys.time(), "%Y-%m-%d")
                PhilMagWordFlagmat <- rbind(PhilMagWordFlagmat,temprow)
              }
          }
        }
        print(paste0(i," out of ",length(files))) #let's user watch as code runs for long searches
      }
      PhilMagWordFlagmat <- PhilMagWordFlagmat[-1,]
      PhilMagWordFlagdf <- as.data.frame(PhilMagWordFlagmat)
      write.table(PhilMagWordFlagdf, PhilMagWordFlagdfPath)
      PhilMagWordFlagdf[1:5,]
  }else{
    print("Loading the previous dataset as PhilMagWordFlagdf")
    PhilMagWordFlagdf <- read.table(PhilMagWordFlagdfPath)
  }
PhilMagWordFlagdf
```


We can then add up the values in PhilMagWordFlagdf to make a table of the frequency of play and work rhetoric, PhilMagFreqmat. It's important to do it this way because it allows us to choose a random KWIC.

```{r PhilMagFreqmat,  eval=FALSE}
  # Adding values from PhilMagWordFlagdf together to get a matrix of normalized frequencies for each category, as PhilMagFreqmat
  PhilMagWordFlagPlaydf <- PhilMagWordFlagdf[grep("Play-Rhetoric",PhilMagWordFlagdf$Category),]
      PhilMagWordFlagWorkdf <- PhilMagWordFlagdf[grep("Work-Rhetoric",PhilMagWordFlagdf$Category),]
      PhilMagFreqmat <- matrix(,ncol=9,nrow=1)
      files <- list.files(path = PhilMagdoclocation, pattern = "txt", full.names = TRUE)
      for (i in 1:length(files)) {
        TempTextName <- gsub(paste0(PhilMagdoclocation,"/"),"",files[i]) #This grabs just the end of the file path.
        TempTextName <- gsub(".txt","",TempTextName) #This removes the .txt from the end of the name.
        tempplaydf <- PhilMagWordFlagPlaydf[grep(TempTextName,PhilMagWordFlagPlaydf$Text),]
        tempworkdf <- PhilMagWordFlagWorkdf[grep(TempTextName,PhilMagWordFlagWorkdf$Text),]
        TempDate <- strsplit(TempTextName,"_")[[1]][2]
        TempLength <- tempplaydf$Total_Lemma[1]
        temprows <- matrix(,ncol=9,nrow=2)
        colnames(temprows) <- c("Text", "Text_ID","Date","Category","Frequency","Total_Lemma","Normalized_Freq","Sample_KWIC","Avg_Lemma_Perc")
        temprows[1:2,1] <- as.character(TempTextName)
        temprows[1:2,2] <- i
        temprows[1:2,3] <- as.character(TempDate)
        temprows[1,4] <- "Play-Rhetoric"
        temprows[2,4] <- "Work-Rhetoric"
        temprows[1,5] <- nrow(tempplaydf)
        temprows[2,5] <- nrow(tempworkdf)
        temprows[1:2,6]<- as.character(TempLength)
        temprows[1,7] <- (as.numeric(temprows[1,5])/as.numeric(temprows[1,6]))*100
        temprows[2,7] <- (as.numeric(temprows[2,5])/as.numeric(temprows[2,6]))*100
        #temprows[1,8]
          if(nrow(tempplaydf) > 0){temprows[1,8] <- as.character(sample(tempplaydf$Short_KWIC,1))}else{temprows[1,8] <- NA}
        #temprows[2,8]
          if(nrow(tempworkdf) >0) {temprows[2,8] <- as.character(sample(tempworkdf$Short_KWIC,1))}else{temprows[2,8] <- NA}
        temprows[1,9] <- mean(as.numeric(as.character(tempplaydf$Lemma_Perc)))
        temprows[2,9] <- mean(as.numeric(as.character(tempworkdf$Lemma_Perc)))
        PhilMagFreqmat <- rbind(PhilMagFreqmat,temprows)
      }
      PhilMagFreqmat <- PhilMagFreqmat[-1,]
      PhilMagFreqdf <- as.data.frame(PhilMagFreqmat)
      PhilMagFreqdf
```

With the data in hand, we can now ask some questions about our corpus, such as: Do references to play or work rhetoric in the *Philosophical Magazine* increase over the course of its run? (Note that here I'm using the substr() function to just pull the year from the date). **INTERSETINGLY, THIS SEEMS TO BE THE OUTLIER, AS REFERENCES TO "WORK" ACTUALLY DECREASE IN THE MIDDLE OF THE CENTURY AND INCREASE LATER.** 

```{r PhilMagWordFreqmat Visual,  eval=FALSE}
# Visualizing PhilMagFreqdf BY DATE
      p <- ggplot(PhilMagFreqdf, aes(y = as.numeric(as.character(Normalized_Freq)), x = as.numeric(substr(Date,1,4)), color = Category, label = Sample_KWIC))
      pg <- geom_point(size=1,pch = 16)
      pl <- p + pg + labs(x = "Date", y = "Normalized Frequency (% of Words in Text)", title = "Appearances of Play and Work Rhetoric within the Philosophical Magazine")
      ggplotly(pl)
```


We can also visualize the terms which most frequently occur around the search terms in the two categories within this corpus. Again, science is on the work side.
```{r PhilMag Work/Play association,  eval=FALSE}
PhilMagWordFlagdf$KWIC <- as.character(PhilMagWordFlagdf$KWIC)
PhilMagWordFlagdf$Text <- as.character(PhilMagWordFlagdf$Text)
corpus <- corpus(PhilMagWordFlagdf, 
                 docid_field="Text", 
                 text_field="KWIC")
group_PhilMagWordFlagdfm <- dfm(corpus, remove=c(stopwords("en"),PhilMagsearchedtermlist), remove_punct=TRUE, remove_numbers = TRUE, groups="Category")
textplot_wordcloud(group_PhilMagWordFlagdfm,max.words=50, colors = RColorBrewer::brewer.pal(8,"Dark2"), comparison=TRUE)
```
