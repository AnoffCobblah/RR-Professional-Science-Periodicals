---
title: "04-RR-RoyalInstitution-PlayWorkRhetoric"
author: "Anoff Nicholas Cobblah"
date: "July 31, 2018"
output: html_document
  html_document:
    number_sections: yes
    toc: true
    toc_depth: 6
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


##### March 2018: "play", "player", "recreation", "work", "worker", and "labor" in *Notices of the Proceedings at the Meetings of the Members of the Royal Institution*

This script combines my Word Flagging and KWIC (tokenizer script) methods in order to create an interactive illustration of the frequency with which the terms "play", "player", "recreation", "work", "worker", and "labor" were referenced in *Notices of the Proceedings at the Meetings of the Members of the Royal Institution*. The goal is to determine the context for work and play rhetoric in that publication.

```{r RoyInst Parameters,  eval=FALSE}
    RoyInstlocation <- paste0(getwd(),"/Documents/Royal-Institution")
    RoyInstdoclocation <- paste0(RoyInstlocation,"/Proceedings")
    RoyInstlongconlength <- 250
    RoyInstshortconlength <- 3
    RoyInstPOSconlength <- 10
    RoyInstplaysearchedtermlist <- c("play", "player", "recreation")
    RoyInstworksearchedtermlist <- c("work", "worker","labor")
    RoyInstsearchedtermlist <- c(RoyInstplaysearchedtermlist,RoyInstworksearchedtermlist)
    RoyInstoutputlocation <- paste0(getwd(),"/WordFlagDataFrames")
    RoyInstWordFlagdfPath <- paste0(RoyInstoutputlocation,"/","RoyInstWordFlagdf.txt")
    RoyInstDocumentSize <- 31964986
```

**IMPORTANT NOTE: Since creating a Word Flag matrix can take a nontrivial amount of time for larger corpuses, this script is designed only to run the program to create a new RoyInstWordFlagdf if there is a change to the dataset in folder "Documents" or if the previous RoyInstWordFlagdf has been deleted.**

To create the data frame compiling every reference to a term, run the following script.

```{r MarRoyInstApp Word Flag,  eval=FALSE}
      if(sum(file.info(list.files(RoyInstdoclocation, all.files = TRUE, recursive = TRUE, full.names=TRUE))$size) == RoyInstDocumentSize) {
        RoyInstDataChange1 <- FALSE
        print("The data in the 'Documents' folder appears not to have changed.")
      }else{
        RoyInstDataChange1 <- TRUE
        print("The data in the 'Documents' folder appears to have been changed. A new RoyInstWordFlagdf will therefore be created. TO UPDATE THIS SCRIPT, PLEASE CHANGE THE RoyInstDocumentSize TO REFLECT THE NEW SIZE OF THE DOCUMENTS.")
        }
      
      if(file.exists(RoyInstWordFlagdfPath) == TRUE) {
        RoyInstDataChange2 <- FALSE
        print("The previous RoyInstWordFlagdf still exists.")
      }else{
        RoyInstDataChange2 <- TRUE
        print("The previous RoyInstwordFlagdf seems to have been moved or deleted.  A new RoyInstWordFlag will therefore be created.")
        }

  if(RoyInstDataChange1|RoyInstDataChange2 == TRUE) {
  
      files <- list.files(path = RoyInstdoclocation, pattern = "txt", full.names = TRUE) #creates vector of txt file names.
      if(file.exists(RoyInstoutputlocation) == FALSE){dir.create(RoyInstoutputlocation)}
      RoyInststemsearchedtermlist <- unique(wordStem(RoyInstsearchedtermlist)) #lemmatizes the list of terms you want to search for.
      RoyInstWordFlagmat <- matrix(,ncol=12,nrow=1)
      for (i in 1:length(files)) {
        fileName <- read_file(files[i])
        Encoding(fileName) <- "UTF-8"  #since tokenize_sentences function requires things to be encoded in UTF-8, need to remove some data.
        fileName <- iconv(fileName, "UTF-8", "UTF-8",sub='')
        ltoken <- tokenize_words(fileName, lowercase = TRUE, stopwords = NULL, simplify = FALSE)
        ltoken <- unlist(ltoken)
        stemltoken <- wordStem(ltoken) #this uses the Snowball library to lemmatize the entire text.
        textID <- i
        for (p in 1:length(RoyInststemsearchedtermlist)) {
          RoyInststemsearchedterm <- RoyInststemsearchedtermlist[p]
          for (j in 1:length(stemltoken)) {
              if (RoyInststemsearchedterm == stemltoken[j]) {
                if (j <= RoyInstlongconlength) {longtempvec <- ltoken[(1:(j+RoyInstlongconlength))]}
                if (j > RoyInstlongconlength) {longtempvec <- ltoken[(j-RoyInstlongconlength):(j+RoyInstlongconlength)]}
                if (j <= RoyInstshortconlength) {shorttempvec <- ltoken[(1:(j+RoyInstshortconlength))]}
                if (j > RoyInstshortconlength) {shorttempvec <- ltoken[(j-RoyInstshortconlength):(j+RoyInstshortconlength)]}
                if (j <= RoyInstPOSconlength) {POStempvec <- ltoken[(1:(j+RoyInstPOSconlength))]}
                if (j > RoyInstPOSconlength) {POStempvec <- ltoken[(j-RoyInstPOSconlength):(j+RoyInstPOSconlength)]}
                TempTextName <- gsub(paste0(RoyInstdoclocation,"/"),"",files[i]) #This grabs just the end of the file path.
                TempTextName <- gsub(".txt","",TempTextName) #This removes the .txt from the end of the name.
                temprow <- matrix(,ncol=12,nrow=1)
                colnames(temprow) <- c("Text", "Text_ID", "RoyInststemsearchedterm","Lemma","Lemma_Perc","KWIC","Total_Lemma","Date","Category","Short_KWIC","POS_KWIC","Current_Date")
                temprow[1,1] <- TempTextName
                temprow[1,2] <- textID
                temprow[1,3] <- RoyInststemsearchedterm
                temprow[1,4] <- j
                temprow[1,5] <- (j/length(stemltoken))*100
                temprow[1,6] <- as.character(paste(longtempvec,sep= " ",collapse=" "))
                temprow[1,7] <- length(stemltoken)
                temprow[1,8] <- strsplit(TempTextName,"_")[[1]][1]
                #Determining Category
                  if(RoyInststemsearchedterm %in% wordStem(RoyInstplaysearchedtermlist)) {temprow[1,9] <- "Play-Rhetoric"}
                  if(RoyInststemsearchedterm %in% wordStem(RoyInstworksearchedtermlist)) {temprow[1,9] <- "Work-Rhetoric"}
                temprow[1,10] <- as.character(paste(shorttempvec,sep= " ",collapse=" "))
                temprow[1,11] <- as.character(paste(POStempvec,sep= " ",collapse=" "))
                temprow[1,12] <- format(Sys.time(), "%Y-%m-%d")
                RoyInstWordFlagmat <- rbind(RoyInstWordFlagmat,temprow)
              }
          }
        }
        print(paste0(i," out of ",length(files))) #let's user watch as code runs for long searches
      }
      RoyInstWordFlagmat <- RoyInstWordFlagmat[-1,]
      RoyInstWordFlagdf <- as.data.frame(RoyInstWordFlagmat)
      write.table(RoyInstWordFlagdf, RoyInstWordFlagdfPath)
      RoyInstWordFlagdf[1:5,]
  }else{
    print("Loading the previous dataset as RoyInstWordFlagdf")
    RoyInstWordFlagdf <- read.table(RoyInstWordFlagdfPath)
  }
RoyInstWordFlagdf
```


We can then add up the values in RoyInstWordFlagdf to make a table of the frequency of play and work rhetoric, RoyInstFreqmat. It's important to do it this way because it allows us to choose a random KWIC.

```{r RoyInstFreqmat,  eval=FALSE}
  # Adding values from RoyInstWordFlagdf together to get a matrix of normalized frequencies for each category, as RoyInstFreqmat
  RoyInstWordFlagPlaydf <- RoyInstWordFlagdf[grep("Play-Rhetoric",RoyInstWordFlagdf$Category),]
      RoyInstWordFlagWorkdf <- RoyInstWordFlagdf[grep("Work-Rhetoric",RoyInstWordFlagdf$Category),]
      RoyInstFreqmat <- matrix(,ncol=9,nrow=1)
      files <- list.files(path = RoyInstdoclocation, pattern = "txt", full.names = TRUE)
      for (i in 1:length(files)) {
        TempTextName <- gsub(paste0(RoyInstdoclocation,"/"),"",files[i]) #This grabs just the end of the file path.
        TempTextName <- gsub(".txt","",TempTextName) #This removes the .txt from the end of the name.
        tempplaydf <- RoyInstWordFlagPlaydf[grep(TempTextName,RoyInstWordFlagPlaydf$Text),]
        tempworkdf <- RoyInstWordFlagWorkdf[grep(TempTextName,RoyInstWordFlagWorkdf$Text),]
        TempDate <- strsplit(TempTextName,"_")[[1]][1]
        TempLength <- tempplaydf$Total_Lemma[1]
        temprows <- matrix(,ncol=9,nrow=2)
        colnames(temprows) <- c("Text", "Text_ID","Date","Category","Frequency","Total_Lemma","Normalized_Freq","Sample_KWIC","Avg_Lemma_Perc")
        temprows[1:2,1] <- as.character(TempTextName)
        temprows[1:2,2] <- i
        temprows[1:2,3] <- as.character(TempDate)
        temprows[1,4] <- "Play-Rhetoric"
        temprows[2,4] <- "Work-Rhetoric"
        temprows[1,5] <- nrow(tempplaydf)
        temprows[2,5] <- nrow(tempworkdf)
        temprows[1:2,6]<- as.character(TempLength)
        temprows[1,7] <- (as.numeric(temprows[1,5])/as.numeric(temprows[1,6]))*100
        temprows[2,7] <- (as.numeric(temprows[2,5])/as.numeric(temprows[2,6]))*100
        #temprows[1,8]
          if(nrow(tempplaydf) > 0){temprows[1,8] <- as.character(sample(tempplaydf$Short_KWIC,1))}else{temprows[1,8] <- NA}
        #temprows[2,8]
          if(nrow(tempworkdf) >0) {temprows[2,8] <- as.character(sample(tempworkdf$Short_KWIC,1))}else{temprows[2,8] <- NA}
        temprows[1,9] <- mean(as.numeric(as.character(tempplaydf$Lemma_Perc)))
        temprows[2,9] <- mean(as.numeric(as.character(tempworkdf$Lemma_Perc)))
        RoyInstFreqmat <- rbind(RoyInstFreqmat,temprows)
      }
      RoyInstFreqmat <- RoyInstFreqmat[-1,]
      RoyInstFreqdf <- as.data.frame(RoyInstFreqmat)
      RoyInstFreqdf
```

With the data in hand, we can now ask some questions about our corpus, such as: Do references to play or work rhetoric in *Proceedings of the Meetings of the Royal Institution* increase over the course of its run? (Note that here I'm using the substr() function to just pull the year from the date). **AS EXPECTED, WE FIND THAT WORK RHETORIC INCREASES, WHILE PLAY STAYS BASICALLY THE SAME.** 

```{r RoyInstWordFreqmat Visual,  eval=FALSE}
# Visualizing RoyInstFreqdf BY DATE
      p <- ggplot(RoyInstFreqdf, aes(y = as.numeric(as.character(Normalized_Freq)), x = as.numeric(substr(Date,1,4)), color = Category, label = Sample_KWIC))
      pg <- geom_point(size=1,pch = 16)
      pl <- p + pg + labs(x = "Date", y = "Normalized Frequency (% of Words in Text)", title = "Appearances of Play and Work Rhetoric within Proceedings \nof the Meetings of the Royal Institution")
      ggplotly(pl)
```


We can also visualize the terms which most frequently occur around the search terms in the two categories within this corpus. Interestingly, work with engines and other thermodynamic categories, while play associated again with music and Shakespeare.
```{r RoyInst Work/Play association,  eval=FALSE}
RoyInstWordFlagdf$KWIC <- as.character(RoyInstWordFlagdf$KWIC)
RoyInstWordFlagdf$Text <- as.character(RoyInstWordFlagdf$Text)
corpus <- corpus(RoyInstWordFlagdf, 
                 docid_field="Text", 
                 text_field="KWIC")
group_RoyInstWordFlagdfm <- dfm(corpus, remove=c(stopwords("en"),RoyInstsearchedtermlist), remove_punct=TRUE, remove_numbers = TRUE, groups="Category")
textplot_wordcloud(group_RoyInstWordFlagdfm,max.words=50, colors = RColorBrewer::brewer.pal(8,"Dark2"), comparison=TRUE)
```
